---
title: 'Statistical tests'
teaching: 10
exercises: 2
---

:::::::::::::::::::::::::::::::::::::: questions 

- How do you write a lesson using R Markdown and `{sandpaper}`?

::::::::::::::::::::::::::::::::::::::::::::::::

::::::::::::::::::::::::::::::::::::: objectives

- Explain how to use markdown with the new lesson template


::::::::::::::::::::::::::::::::::::::::::::::::

:::: instructor
Den her side er virkelig ikke egnet til undervisningsbrug. Det er oversigten
med eksempler og ret korte forklaringer.
Hele siden kan nok med fordel deles ret meget op.
::::

A collection of statistical tests

For all tests, the approach is:

1. Formulate hypotheses
2. Calculate test statistic
3. Determine p-value
4. Make decision




## Enkeltprøve-tests

### One-sample chi-square test

EJ KORREKTURLÆST

#### Used for

Testing whether observed categorical frequencies differ from expected frequencies under a specified distribution.

**Real-world example:** Checking if the observed M&M candy color proportions match the manufacturer’s claimed distribution.

#### Assumptions
- Observations are independent.  
- Categories are mutually exclusive and collectively exhaustive.  
- Expected count in each category is at least 5 (for the chi-square approximation to be valid).

#### Strengths
- Simple to compute and interpret.  
- Does not require the data to be normally distributed.  
- Applicable to any number of categories.

#### Weaknesses
- Sensitive to small expected counts (violates asymptotic approximation).  
- Does not indicate which categories contribute most to the discrepancy without further investigation.  
- Requires independence; cannot be used for paired or repeated measures.

#### Example

##### Hypothesis
- **Null hypothesis (H₀):** The proportions of M&M colors equal the manufacturer’s claimed distribution.  
- **Alternative hypothesis (H₁):** At least one color’s proportion differs from the claimed distribution.


```{r one_sample_chi_square_test}
# Observed counts of M&M colors:
observed <- c(red = 20, blue = 25, green = 15, brown = 18, orange = 12, yellow = 10)

# Manufacturer's claimed proportions:
p_expected <- c(red = 0.20, blue = 0.20, green = 0.20, brown = 0.20, orange = 0.10, yellow = 0.10)

# Perform one-sample chi-square goodness-of-fit test:
test_result <- chisq.test(x = observed, p = p_expected)

# Display results:
test_result
```

Interpretation:
The test yields χ² = `r round(test_result$statistic, 2)` with a p-value = `r signif(test_result$p.value, 3)`. We
`r if(test_result$p.value < 0.05) "reject the null hypothesis" else "fail to reject the null hypothesis"`.
Thus, there is
`r if(test_result$p.value < 0.05) "evidence that the observed M&M colour proportions differ from the claimed distribution." else "no evidence to conclude a difference from the claimed distribution."`.


### One-sample z test

EJ KORREKTURLÆST!

#### Used for

- Testing whether the mean of a single sample differs from a known population mean when the population standard deviation is known.  
- **Real-world example:** Checking if the average diameter of manufactured ball bearings equals the specified 5.00 cm when σ is known.

#### Assumptions
- Sample is a simple random sample from the population.  
- Observations are independent.  
- Population standard deviation (σ) is known.  
- The sampling distribution of the mean is approximately normal (either the population is normal or n is large, e.g. ≥ 30).

#### Strengths
- More powerful than the t-test when σ is truly known.  
- Simple calculation and interpretation.  
- Relies on the normal distribution, which is well understood.

#### Weaknesses
- The true population σ is only very rarely known in practice.  
- Sensitive to departures from normality for small samples.  
- Misspecification of σ leads to incorrect inferences.

#### Example

##### Hypothesis
- **Null hypothesis (H₀):** The true mean diameter μ = 5.00 cm.  
- **Alternative hypothesis (H₁):** μ ≠ 5.00 cm.

```{r one_sample_z_test}
# Sample of diameters (cm) for 25 ball bearings:
diameters <- c(5.03, 4.97, 5.01, 5.05, 4.99, 5.02, 5.00, 5.04, 4.96, 5.00,
               5.01, 4.98, 5.02, 5.03, 4.94, 5.00, 5.02, 4.99, 5.01, 5.03,
               4.98, 5.00, 5.04, 4.97, 5.02)

# Known population standard deviation:
sigma <- 0.05

# Hypothesized mean:
mu0 <- 5.00

# Compute test statistic:
n <- length(diameters)
xbar <- mean(diameters)
z_stat <- (xbar - mu0) / (sigma / sqrt(n))

# Two-sided p-value:
p_value <- 2 * (1 - pnorm(abs(z_stat)))

# Output results:
z_stat; p_value
``` 


Interpretation:
The sample mean is `r round(xbar, 3)` cm. The z-statistic is `r round(z_stat, 2)` 
with a two-sided p-value of `r signif(p_value, 3)`. We
`r if(p_value < 0.05) "reject the null hypothesis" else "fail to reject the null hypothesis"`.
Thus, there is
`r if(p_value < 0.05) "evidence that the average diameter differs from 5.00 cm." else "no evidence to conclude a difference from the specified diameter of 5.00 cm."`


### One-sample t test

EJ KORREKTURLÆST!

#### Used for
- Testing whether the mean of a single sample differs from a known or hypothesized population mean when the population standard deviation is unknown.  
- **Real-world example:** Determining if the average exam score of a class differs from the passing threshold of 70%.

#### Assumptions
- Sample is a simple random sample from the population.  
- Observations are independent.  
- The data are approximately normally distributed (especially important for small samples; n ≥ 30 reduces sensitivity).

#### Strengths
- Does not require knowing the population standard deviation.  
- Robust to mild departures from normality for moderate-to-large sample sizes.  
- Widely applicable and easily implemented.

#### Weaknesses
- Sensitive to outliers in small samples.  
- Performance degrades if normality assumption is seriously violated and n is small.  
- Degrees of freedom reduce power relative to z-test.

#### Example

##### Hypothesis

- **Null hypothesis (H₀):** The true mean exam score μ = 70.  
- **Alternative hypothesis (H₁):** μ ≠ 70.

```{r one_sample_t_test}
# Sample of exam scores for 20 students:
scores <- c(68, 74, 71, 69, 73, 65, 77, 72, 70, 66,
            75, 68, 71, 69, 74, 67, 72, 70, 73, 68)

# Hypothesized mean:
mu0 <- 70

# Perform one-sample t-test:
test_result <- t.test(x = scores, mu = mu0)

# Display results:
test_result
```

Interpretation:
The sample mean is `r round(mean(scores), 2)`. The t-statistic is `r round(test_result$statistic, 2)` with `r test_result$parameter` degrees of freedom and a two-sided p-value of `r signif(test_result$p.value, 3)`. We
`r if(test_result$p.value < 0.05) "reject the null hypothesis" else "fail to reject the null hypothesis"`.
Thus, there is
`r if(test_result$p.value < 0.05) "evidence that the class’s average score differs from 70." else "no evidence to conclude the average score differs from the passing threshold of 70."`


### One-sample Poisson test

EJ KORREKTURLÆST!

#### Used for
- Testing whether the observed count of events in a fixed period differs from a hypothesized Poisson rate.  
- **Real-world example:** Checking if the number of customer arrivals per hour at a call center matches the expected rate of 30 calls/hour.

#### Assumptions
- Events occur independently.  
- The rate of occurrence (λ) is constant over the observation period.  
- The count of events in non-overlapping intervals is independent.

#### Strengths
- Exact test based on the Poisson distribution (no large-sample approximation needed).  
- Valid for small counts and rare events.  
- Simple to implement in R via `poisson.test()`.

#### Weaknesses
- Sensitive to violations of the Poisson assumptions (e.g., overdispersion or time-varying rate).  
- Only assesses the overall rate, not the dispersion or clustering of events.  
- Cannot handle covariates or more complex rate structures.

#### Example

##### Hypothesis
- **Null hypothesis (H₀):** The event rate λ = 30 calls/hour.  
- **Alternative hypothesis (H₁):** λ ≠ 30 calls/hour.

```{r one_sample_poisson_test}
# Observed number of calls in one hour:
observed_calls <- 36

# Hypothesized rate (calls per hour):
lambda0 <- 30

# Perform one-sample Poisson test (two-sided):
test_result <- poisson.test(x = observed_calls, T = 1, r = lambda0, alternative = "two.sided")

# Display results:
test_result
```

Interpretation:
The test reports an observed count of `r test_result$statistic` calls versus an expected 30 calls, yielding a p-value of `r signif(test_result$p.value, 3)`. We
`r if(test_result$p.value < 0.05) "reject the null hypothesis" else "fail to reject the null hypothesis"`.
Thus, there is
`r if(test_result$p.value < 0.05) "evidence that the true call rate differs from 30 calls/hour." else "no evidence to conclude the call rate differs from 30 calls/hour."`


### Shapiro–Wilk test for normalitet

### Kolmogorov–Smirnov én-prøve-test (goodness-of-fit)

### χ² goodness-of-fit test

## To-prøve-tests og parrede tests

### Two-sample F test


er det det samme som Two-sample F-test for variance?

We use this when we want to determine if two independent samples originate
from populations with the same variance.


### Paired t-test

EJ KORREKTURLÆST


### Two-sample t test (equal variances)

EJ KORREKTURLÆST

### Two-sample t test (unequal variances)

EJ KORREKTURLÆST

### Mann–Whitney U-test (Wilcoxon rank-sum)

EJ KORREKTURLÆST

### Wilcoxon signed-rank test

EJ KORREKTURLÆST

### Kolmogorov–Smirnov to-prøve-test

EJ KORREKTURLÆST


### Levene’s test for homoskedasticitet

EJ KORREKTURLÆST

#### Used for
- Testing whether multiple groups have equal variances.  
- **Real-world example:** Checking if the variability in patient blood pressure differs between three different clinics.

#### Assumptions
- Observations are independent.  
- The underlying distributions within each group are approximately symmetric (Levene’s test is robust to non-normality but assumes no extreme skew).

#### Strengths
- More robust to departures from normality than Bartlett’s test.  
- Applicable to two or more groups.  
- Simple to implement and interpret.

#### Weaknesses
- Less powerful than tests that assume normality when data truly are normal.  
- Can be sensitive to extreme outliers despite its robustness.  
- Does not indicate which groups differ in variance without follow-up comparisons.

#### Example

##### Hypothesis
- **Null hypothesis (H₀):** All groups have equal variances (σ₁² = σ₂² = … = σₖ²).  
- **Alternative hypothesis (H₁):** At least one group’s variance differs.

```{r levene_test}
# Simulate data for three groups (n = 10 each):
set.seed(123)
group   <- factor(rep(c("ClinicA", "ClinicB", "ClinicC"), each = 10))
scores  <- c(rnorm(10, mean = 120, sd = 5),
             rnorm(10, mean = 120, sd = 8),
             rnorm(10, mean = 120, sd = 5))
df      <- data.frame(group, scores)

# Perform Levene’s test for homogeneity of variances:
library(car)
levene_result <- leveneTest(scores ~ group, data = df)

# Show results:
levene_result
``` 

Interpretation:
Levene’s test yields an F-statistic of `r round(levene_result$F value[1], 2)` 
with a p-value of `r signif(levene_result$Pr(>F)[1], 3)`. We
`r if(levene_result$Pr(>F)[1] < 0.05) "reject the null hypothesis" else "fail to reject the null hypothesis"`.
This means there is
`r if(levene_result$Pr(>F)[1] < 0.05) "evidence that at least one clinic’s blood pressure variability differs from the others." else "no evidence of differing variances across clinics."`









### Bartlett’s test for homoskedasticitet

EJ KORREKTURLÆST

## Variansanalyse (ANOVA/ANCOVA)

### One-way ANOVA

EJ KORREKTURLÆST

### One-way ANCOVA

EJ KORREKTURLÆST

### Welch’s ANOVA (uden antagelse om lige varianser)

EJ KORREKTURLÆST

### Repeated-measures ANOVA

EJ KORREKTURLÆST

### Friedman test (nonparametrisk gentagne målinger)

EJ KORREKTURLÆST

### Post-hoc: Tukey HSD

EJ KORREKTURLÆST

### Post-hoc: Dunnett’s test

EJ KORREKTURLÆST

### Post-hoc: Bonferroni korrektion

EJ KORREKTURLÆST

## Ikke-parametriske k-prøve-tests



### Kruskal–Wallis test

EJ KORREKTURLÆST

### Rank correlation

EJ KORREKTURLÆST

### Anderson–Darling test

EJ KORREKTURLÆST

## Regression og korrelation


### Simple linear regression

EJ KORREKTURLÆST

### Multiple regression

EJ KORREKTURLÆST

### Pearson correlation

EJ KORREKTURLÆST

### Spearman’s rank correlation

EJ KORREKTURLÆST

### Kendall’s tau

EJ KORREKTURLÆST

### Multiple logistic regression

EJ KORREKTURLÆST

### Poisson regression

EJ KORREKTURLÆST

### Negative binomial regression

EJ KORREKTURLÆST

### Ordinal logistic regression

EJ KORREKTURLÆST

### Linear mixed-effects modeller (LME)

EJ KORREKTURLÆST

### Generalized linear mixed-effects modeller (GLMM)

EJ KORREKTURLÆST

### Generalized Estimating Equations (GEE)

EJ KORREKTURLÆST

## Kontingenstabel- og proportions-tests

### Contingency-table methods (χ² osv.)

EJ KORREKTURLÆST

### McNemar’s test

EJ KORREKTURLÆST

### Fisher’s exact test

EJ KORREKTURLÆST

### Barnard’s exact test

EJ KORREKTURLÆST

### Cochran–Armitage trend test (ordinal tabel)

EJ KORREKTURLÆST


### Cochran’s Q test (≥3 matched proportions)

EJ KORREKTURLÆST

### Stuart–Maxwell test (marginal homogenitet)

EJ KORREKTURLÆST

### Two-sample test for binomial proportions / Mantel–Haenszel test

EJ KORREKTURLÆST

### Chi-square test for R×C-tabeller

EJ KORREKTURLÆST

### Chi-square test for trend (Mantel-extension)

EJ KORREKTURLÆST

### Chi-square test for heterogenitet (2×k-tabeller)

EJ KORREKTURLÆST

## Incidens- og rate-tests



### One-sample test for incidence rates

EJ KORREKTURLÆST

### Two-sample comparison of incidence rates

EJ KORREKTURLÆST

### Trend-test for incidence rates over flere eksponeringsgrupper

EJ KORREKTURLÆST

### Exact rate ratio test

EJ KORREKTURLÆST

## Overlevelsesanalyse

### Log-rank test

EJ KORREKTURLÆST

### Parametric survival methods (Weibull)

EJ KORREKTURLÆST

### Cox proportional hazards model

EJ KORREKTURLÆST

### Accelerated Failure Time (AFT) modeller (eksponentiel, log-logistisk, …)

EJ KORREKTURLÆST

### Gray’s test for konkurrentrisiko

EJ KORREKTURLÆST

### Test af proportional hazards-antagelsen (Schoenfeld residualer)

EJ KORREKTURLÆST

## Aftale- og concordance-mål



### Kappa statistic

EJ KORREKTURLÆST



### Intraclass Correlation Coefficient (ICC)

EJ KORREKTURLÆST

#### Used for
- Assessing the reliability or agreement of quantitative measurements made by two or more raters.  
- **Real-world example:** Determining how consistently three radiologists measure tumor size on MRI scans.

#### Assumptions
- Measurements are continuous and approximately normally distributed.  
- Raters are randomly selected (for the “random‐effects” model) or fixed (for the “fixed‐effects” model), depending on choice.  
- No interaction between subjects and raters (i.e., rater effects are consistent across subjects).  
- Balanced design: each subject is rated by the same set of raters.

#### Strengths
- Quantifies both consistency and absolute agreement, with different model/type options.  
- Can accommodate any number of raters and subjects.  
- Provides confidence intervals and tests for ICC.

#### Weaknesses
- Sensitive to violations of normality and homogeneity of variance.  
- Choice of model (one‐way vs. two‐way) and type (consistency vs. agreement) affects results.  
- Requires balanced data; missing ratings complicate estimation.

#### Example

##### Hypothesis
- **Null hypothesis (H₀):** The intraclass correlation coefficient ICC = 0 (no reliability beyond chance).  
- **Alternative hypothesis (H₁):** ICC > 0 (measurements are more reliable than chance).

```{r intraclass_correlation_coefficient}
library(irr)

# Simulate ratings of 10 subjects by 3 raters:
set.seed(42)
ratings <- data.frame(
  rater1 = round(rnorm(10, mean = 50, sd = 5)),
  rater2 = round(rnorm(10, mean = 50, sd = 5)),
  rater3 = round(rnorm(10, mean = 50, sd = 5))
)

# Compute two-way random effects, absolute agreement, single rater ICC:
icc_result <- icc(ratings,
                  model = "twoway",
                  type  = "agreement",
                  unit  = "single")

# Display results:
icc_result
```
Interpretation:
The estimated ICC is `r round(icc_result$value, 2)` with a 95% CI [`r round(icc_result$lbound, 2)`, `r round(icc_result$ubound, 2)`] and p-value = `r signif(icc_result$p.value, 3)`. We
`r if(icc_result$p.value < 0.05) "reject the null hypothesis" else "fail to reject the null hypothesis"`.
This indicates that
`r if(icc_result$p.value < 0.05) "there is statistically significant reliability among the raters." else "there is no evidence of reliability beyond chance among the raters."`

### Bland–Altman analysis

EJ KORREKTURLÆST

#### Used for
Assessing agreement between two quantitative measurement methods by examining 
the mean difference (bias) and the limits of agreement. It tests if any difference
is constant across the range of measurements, and if there is heteroskedasticity
in the data (are there differences that are dependent on measurement levels)
**Real-world example:** Comparing blood pressure readings from a new wrist monitor and a standard sphygmomanometer.


#### Assumptions
- Paired measurements on the same subjects.  
- Differences (method A – method B) are approximately normally distributed.  
- No strong relationship between the magnitude of the measurement and the difference (homoscedasticity).

#### Strengths
- Provides both a visual (Bland–Altman plot) and numerical summary (bias and limits) of agreement.  
- Easy to interpret clinically: shows how far apart two methods can differ for most observations.  
- Does not rely on correlation, which can be misleading for agreement.

#### Weaknesses
- Assumes constant bias across range of measurements.  
- Sensitive to outliers, which can widen limits of agreement.  
- Requires adequate sample size (n ≥ 30 preferred) to estimate limits reliably.

#### Example

##### Hypothesis
- **Null hypothesis (H₀):** Mean difference between methods A and B is zero (no systematic bias).  
- **Alternative hypothesis (H₁):** Mean difference ≠ 0 (systematic bias exists).

```{r bland_altman}
# Simulated paired blood pressure measurements (mmHg) on 12 subjects:
wrist   <- c(120, 122, 118, 121, 119, 117, 123, 120, 118, 119, 122, 121)
sphyg   <- c(119, 121, 117, 122, 118, 116, 124, 119, 117, 120, 121, 122)

# Compute differences and means:
diffs    <- wrist - sphyg
means    <- (wrist + sphyg) / 2

# Calculate bias and limits of agreement:
bias     <- mean(diffs)
sd_diff  <- sd(diffs)
loa_up   <- bias + 1.96 * sd_diff
loa_low  <- bias - 1.96 * sd_diff

# Test for zero bias:
t_test   <- t.test(diffs, mu = 0)

# Bland–Altman plot:
library(ggplot2)
ba_df <- data.frame(mean = means, diff = diffs)
ggplot(ba_df, aes(x = mean, y = diff)) +
  geom_point() +
  geom_hline(yintercept = bias,    linetype = "solid") +
  geom_hline(yintercept = loa_up,   linetype = "dashed") +
  geom_hline(yintercept = loa_low,  linetype = "dashed") +
  labs(title = "Bland–Altman Plot",
       x = "Mean of Wrist & Sphyg Measurements",
       y = "Difference (Wrist – Sphyg)")

# Print numerical results:
bias; loa_low; loa_up; t_test
```

The mean difference (bias) is `r round(bias, 2)` units, with 95% limits of 
agreement from `r round(loa_low, 2)` to `r round(loa_up, 2)` units. 
The t-test for zero bias yields a p-value of `r signif(t_test$p.value, 3)`, so we
`r if(t_test$p.value < 0.05) "reject the null hypothesis" else "fail to reject the null hypothesis"`.
This indicates that there is
`r if(t_test$p.value < 0.05) "evidence of systematic bias between methods A and B." else "no statistically significant bias; the two methods agree on average."`




::::::::::::::::::::::::::::::::::::: keypoints 

- Use `.md` files for episodes when you want static content


::::::::::::::::::::::::::::::::::::::::::::::::



