---
title: 'The normal distribution'
teaching: 10
exercises: 2
---

:::::::::::::::::::::::::::::::::::::: questions 

- What even is a normal distribution?

::::::::::::::::::::::::::::::::::::::::::::::::

::::::::::::::::::::::::::::::::::::: objectives

- Explain how to use markdown with the new lesson template
- Demonstrate how to include pieces of code, figures, and nested challenge blocks

::::::::::::::::::::::::::::::::::::::::::::::::

```{r setup, echo = FALSE, warning=FALSE, message=FALSE}
library(tidyverse)
```


## The Normal Distribution

:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: instructor

Inline instructor notes can help inform instructors of timing challenges
associated with the lessons. They appear in the "Instructor View"

::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

## What is the normal distribution

A probability distribution is a mathematical function, that describes
the likelyhood of different outcomes in a random experiment. It gives us
probabilities for all possible outcomes, and is normalised so that the sum
of all the probabilities is 1. 

Probability distribtutions can be discrete, or they can be continuous. The normal
distribution is just one of several different continuous probability distributions. 

The normal distribution is especially important, for a number of reasons:

1. If we take a lot of samples from a population and calculate the averages of 
a given variable in those samples, the averages, or means will be normally 
distributed. This is know as the Central Limit Theorem [KAN VI SÆTTE ET LINK IND?]

2. Many natural (and human made) processes follow a normal distribution.

3. The normal distribution have useful mathematical properties. It might not 
appear to be simple working with the normal distribution. But the alternative is
worse.

4. Many statistical methods and tests are based on assumptions of normality.

## How does it look - mathematically?
The normal distribution follows this formula:

$$
f(x) = \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}
$$

If a variable in our population is normally distributed, have a mean $\mu$ and a 
standard deviation $\sigma$, we can find the probability of observing the value 
$x$ of the varibel by plugging in the values, and calculate $f(x)$.

Note that we are here working with the population mean and standard deviation. 
Those are the "true" mean and standard deviation for the _entire_ universe. That 
is signified by using the greek letters $\mu$ and $\sigma$. In practise
we do not know what those true values are.

### What does it mean that our data is normally distributed

We have an entire section on that - but in short: The probabilities we get 
from the formula above should match the frequencies we observe in our data.

## How does it look- graphically?

It is useful to be able to compare the distributions of different variables.
That can be difficult if one have a mean of 1000, and the other have a mean
of 2. Therefore we often work with standardized normal distributions, where
we transform the data to have a mean of 0 and a standard deviation of 1. So
let us look at the standardized normal distribution.

If we plot it, it looks like this:

![The Normal Distribution. Source: https://en.m.wikipedia.org/wiki/File:The_Normal_Distribution.svg](fig/The_Normal_Distribution.svg){alt='The Normal Distribution.'}
The area under the curve is 1, equivalent to 100%.

The normal distribution have a lot of nice mathematical properties, some of which
are indicated on the graph. 

## So - what _is_ the probability?

The normal distribution curve tell what the probability density for a given observation
is. But in general we are interested in the probability that something is larger,
or smaller, than something. Or between certain values. 

Rather that plotting the probability density, we can plot the cumulative density.

```{r cdf-plot, echo = FALSE}

# Definer normalfordelingens parametre
mean <- 0     # Middelværdi
sd <- 1       # Standardafvigelse

# Beregn kvantiler for normalfordelingen
quantiler <- qnorm(c(0.25, 0.5, 0.75), mean = mean, sd = sd)

# Opret data til CDF og segmenter
x_values <- seq(-4, 4, length.out = 1000)
cdf_values <- pnorm(x_values, mean = mean, sd = sd)
cdf_data <- tibble(x = x_values, cdf = cdf_values)

h_data <- tibble(
  x = rep(-4, 3),  # Horisontale linjer starter ved y-aksen (-4 på x-aksen)
  y = c(0.25, 0.5, 0.75),
  xend = quantiler,
  yend = c(0.25, 0.5, 0.75)
)

v_data <- tibble(
  x = quantiler,
  xend = quantiler,
  y = rep(0, 3),
  yend = c(0.25, 0.5, 0.75)
)

# Plot CDF med linjer for kvantiler
ggplot(cdf_data, aes(x = x, y = cdf)) +
  geom_line(color = "blue", linewidth = 1) +  # CDF-kurven
  geom_segment(data = v_data, aes(x = x, y = y, xend = xend, yend = yend),
               color = "red", linewidth = 1) +  # Vertikale linjer
  geom_segment(data = h_data, aes(x = x, y = y, xend = xend, yend = yend),
               color = "red", linewidth = 1) +  # Horisontale linjer
  scale_y_continuous(limits = c(0, 1), expand = c(0, 0)) +  # Y-akse fra 0 til 1
  scale_x_continuous(limits = c(-4, 4), expand = c(0, 0)) +  # X-akse fra -4 til 4
  labs(
    title = "CDF of Normal distribution",
    x = "x",
    y = "Cumulative Probability"
  ) +
  theme_classic()

```

Note that we also find the cumulitive probability in the original plot of 
the normal distribution - now it is a bit more direct.

This allow us to see that the probability of observing a value that is 2 standard
deviations smaller than the mean is rather small. 

We can also, more indirectly, note that the probability of observing a value that
is 2 standard deviations larger than the mean is rather small. Note that the
probability of an observation that is smaller than 2 standard deviations larger
than the mean is 97.7% (hard to read on the graph, but we will get to that). 
Since the total probability is 100%, the probability of an observation being larger
than 2 standard deviations is 100 - 97.7 = 2.3%


## Do not read the graph - do the calculation

Instead of trying to measure the values on the graph, we can do the calculations
directly. 

R provides us with a set of functions:



* *pnorm* returns the probability of having a smaller value than x
* *qnorm* the value x corresponding to a given probability
* *dnorm* returns the probability density of the normal distribution at a given x.

We have an additional *rnorm* that returns a random value, drawn from a normal
distribution.

:::: challenge
## Try it your self!

Assuming that our observations are normally distributed with a mean of 0 and
a standard deviation of 1.

What is the probability of an observation x < 2?

:::: solution
```{r}
pnorm(2)
```

About 98% of the observations are smaller than 2

::::

::::
:::: challenge
Making the same assumptions, what is the value of the observation, for which
42% of the observations is smaller?

:::: solution
```{r}
qnorm(0.42)
```

42% of the observations are smaller than -0.2

::::
::::


## What about other means and standard deviations?

Being able to find out what the probablity of some observation being smaller when
the mean is 0 and the standard deviation is 1, is nice. But this is not a common
problem.

Rather we might know that adult men in a given country have an average height
of 183 cm, and that the standard deviation of their height is 9.7 cm. 

What is the probability to encounter a man that is taller than 2 meters?

The R-functions handle this easily, we "simply" specify the mean and standard 
deviation in the function:

```{r}
1 - pnorm(200, mean = 183, sd = 9.7)
```
The function calculate the probability of a man being shorter than 200 cm,
if the distribution is normal and the mean and standard devation is 183 and
9.7 respectively. The probability of the man having a height is 1 (equivalent to 100%).
So if the probability of the man being shorter than 200 cm is 96%, the probability
of him being taller than 200 cm is 4%


:::: spoiler
## How does that work?

We have a lot of men with an average height of 183. They all have an individual
heigth. If we subtract 183 from their height, and use that as a measurement of 
their height, that will have a mean of 0. 

We are not going into the details, but if we divide all the heights with the
original standard deviation, and do all the math, we will discover that 
the standard deviation of the new heights will be 1.

Therefore, if we subtract 183 from all the individual heights, and divide them
by 9.7, the resulting measurements of the heights have a mean of 0 and a standard 
deviation of 1. Bringing all that together, we get:

```{r}
1 - pnorm((200-183)/9.7)
```

::::

:::: challenge
## How many men are in an interval?

How many men have a height between 170 and 190 cm?

Assume mean = 183 cm and sd = 9.7

:::: spoiler
## Hint
What proportion of men are shorter than 190 cm? And what proportion of men
are shorter than 170 cm?
::::

:::: solution

```{r}
pnorm(190, mean =183, sd = 9.7 )  - pnorm(170, mean = 183, sd = 9.7)
```


::::

::::


## CLT

The Central Limit Theorem allows us to assume that the mean of our data is 
nromally distributed even when the data itself is _not_ normally distributed.

I praksis bruger vi t-fordelingen, der ser lidt anderledes ud - vi har nemlig 
ikke kendskab til hele populationens sande middelværdi og varians. t-fordelingen
har tykkere haler, der giver os større sikkerhed for vores konklusioner.

Hvad gør vi så? Hvis vi tager i princippet uendeligt mange stikprøver, samples,
og beregner middelværdierne, så vil disse middelværdier følge normalfordelingen.

hvis vi fremstiller linealer, og har en tese om at de er præcist 20 cm lange,
som de skal være. det er mu

Nu tager vi en stikprøve på størrelsen "n" fra produktionen. Måler dem, og beregner gennemsnittet.

Måler vi præcist nok, vil det gennemsnit formentlig adskille sig fra 20 cm. Det
gennemsnit er X-bar. 

I dette tilfælde antager vi at vi kender standardafvigelsen for vores produktion.

Hvis vi normerer alle vores målinger, så gennemsnittet er 0. Det gør vi ved at trække
gennemsnittet fra alle målinger. Og så standardafvigelsen er 1. Det gør vi ved at 
dividere alle målinger med standardafvigelsen.

Så vil gennemsnittet af vores stikprøve, fordi CLT, følge en normalfordeling.
Og vi kan se hvor det gennemsnit, denne z-score, placerer sig på den sande normalfordeling.

og ud fra de matematiske egenskaber fra normalfordelingen, kan vi se hvor underlig den
middelværdi vi måler, er.

og det er stadig ikke en specielt god forklaring...



### Fordelingsfunktionerne i R.

De hyppigst forekommende fordelinger har hver deres sæt af funktioner.

#### rnorm
I samme familie finder vi runif, rbeta og en del andre:
```{r rnorm-example}
rnorm(5, mean = 0, sd = 1 )
```
Den returnerer (her) fem tilfældige værdier fra en normalfordeling med (her) 
middelværdi 0 og standardafvigelse 1.



#### dnorm
densiteten. I plottet er det værdien på y-aksen af kurven. 

#### pnorm
Den kumulative fordeling. Hvis x er 0, er arealet fra minus uendelig til 0
lig pnorm(0). Og hvis vi bruger defaulet mean og sd, er det så 0.5.
Sandsynligheden for en værdi mindre end x.

#### qnorm
det er så den omvendte funktion af pnorm. Husk det på at et q er det omvendte af
et p.

i pnorm finder vi sandsynligheden for at værdien er mindre end x. I qnorm finder
vi x for en given sandsynlighed.

## Er ting normalfordelte?

Normalfordelingen kaldes normal fordi Karl Pearson og Francis Galton i det 19.
århundrede observerede at det var en statistisk fordeling der forklarede 
rigtig mange fænomener i befolkningsdata. Højde, vægt, blodtryk, intelligenskvotienter
mv. Faktisk var det den der forklarede flest (af de ting de nu undersøgte).

Og så er det i øvrigt den fordeling som middelværdier af stikprøver vil tilnærme sig
jf. den centrale grænseværdisætning.

Så den er normal fordi det er normen, den hyppigst forekommende. Ikke at forveksle
med en mere løs, dagligsprogs, normativ (pun intended) anvendelse af ordet norm. Normalen i 
en statistisk sammenhæng er ganske enkelt den hyppigst forekommende observation.

Det i statistisk forstand normale, normen, er at have brune øjne (>50% af klodens
befolkning har brune øjne). Det betyder ikke at der er noget galt med at have
blå øjne.

Og rigtig mange ting er ret tæt på at være normalfordelte. Men i virkeligheden
er der ikke mange fænomener der følger normalfordelingen fuldstændig. Et eksempel:

Serum (en del af blod) Molybdæn (der er et essentielt sporstof i human fysiologi), har en 
middelværdi på 1.55 og en standardafvigelse på 0.74 hos normale, raske mennesker.

Rifai, N. (2017). Tietz textbook of clinical chemistry and molecular diagnostics : Tietz textbook of clinical chemistry and molecular diagnostics - e-book. Elsevier - Health Sciences Division.

Hvis vi antager at serum-Molybdæn er normalfordelt i populationen, kan vi 
beregne hvor stor en andel af den normale raske befolkning i danmark, der har 
en Molybdæn-koncentration under 0:

```{r pnorm-negative}
pnorm(0, mean = 1.55, sd = 0.74)

```
Hvilket vil sige at vi forventer at lidt over 100.000 danskere har et negativt 
indhold af Molybdæn i blodet. Hvilket er fysisk umuligt.
Hvorfor går det så godt alligevel? Fordi serum molybdæn er normalfordelt _nok_.




::::::::::::::::::::::::::::::::::::: keypoints 

- Use `.md` files for episodes when you want static content
- Use `.Rmd` files for episodes when you need to generate output
- Run `sandpaper::check_lesson()` to identify any issues with your lesson
- Run `sandpaper::build_lesson()` to preview your lesson locally

::::::::::::::::::::::::::::::::::::::::::::::::

